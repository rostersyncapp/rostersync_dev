name: Supabase to Backblaze Backup

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install PostgreSQL Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Dump and Compress Database
        env:
          DB_PASS: ${{ secrets.SUPABASE_DB_PASSWORD }}
          PROJECT_ID: rddqcxfalrlmlvirjlca
          HOST: aws-1-us-east-2.pooler.supabase.com
        run: |
          # We pass the project ID via the 'options' parameter. 
          # This is the most explicit way to route through the Supabase pooler.
          pg_dump "postgres://postgres.$PROJECT_ID:$DB_PASS@$HOST:5432/postgres?sslmode=require&options=-c%20project=$PROJECT_ID" > backup.sql
          gzip backup.sql

      - name: Upload to Backblaze B2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.B2_APPLICATION_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.B2_APPLICATION_KEY }}
          AWS_DEFAULT_REGION: us-west-004 
        run: |
          FILENAME="rostersync_db_$(date +'%Y-%m-%d_%H-%M').sql.gz"
          aws s3 cp backup.sql.gz "s3://${{ secrets.B2_BUCKET_NAME }}/$FILENAME" \
            --endpoint-url "${{ secrets.B2_ENDPOINT }}"
